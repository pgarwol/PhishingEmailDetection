{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predykcja ataku phishingowego w wiadomości <b>e-mail</b> za pomocą <b><i>nadzorowanego nauczania maszynowego</i></b>\n",
    "Dataset: \n",
    "<ul>\n",
    "    <li><i><b>Phishing Email Curated Datasets</b></i></li>\n",
    "    <ul>\n",
    "        <li><a href=\"https://zenodo.org/records/8339691\" target=\"_blank\">https://zenodo.org/records/8339691</a></li>\n",
    "    </ul>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobieranie niezbędnych modułów\n",
    "<ul>\n",
    "    <li> pandas - praca z <i>Data Framami</i></li>\n",
    "    <li> numpy - obliczenia</li>\n",
    "    <li> matplotlib.pyplot - wizualizacja</li>\n",
    "    <li> sklearn - wszelakie narzędzia do <i>Machine Learningu</i></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import sklearn.metrics as skm\n",
    "\n",
    "import import_ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wczytanie uprzednio przygotowanego Data Framu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  label  urls_count  protocol  contains_ip  url_length  \\\n",
      "0           0    1.0         1.0       0.0          0.0        21.0   \n",
      "1           1    1.0         1.0       0.0          0.0        25.0   \n",
      "2           2    1.0         3.0       0.0          0.0       110.0   \n",
      "3           3    0.0         3.0       0.0          0.0        22.0   \n",
      "4           4    1.0         1.0       0.0          0.0       136.0   \n",
      "\n",
      "   TLD_alpha  subdomain_level  slash_count  dots_count  hyphens_count  \\\n",
      "0        1.0              0.0          3.0         1.0            0.0   \n",
      "1        1.0              1.0          2.0         2.0            0.0   \n",
      "2        1.0              1.0          6.0         5.0            0.0   \n",
      "3        0.0              1.0          2.0         2.0            0.0   \n",
      "4        1.0              2.0          4.0         4.0            2.0   \n",
      "\n",
      "   has_non_latin  \n",
      "0            0.0  \n",
      "1            0.0  \n",
      "2            0.0  \n",
      "3            0.0  \n",
      "4            0.0  \n"
     ]
    }
   ],
   "source": [
    "learning_set = pd.read_csv('ML_DataFrame.csv')\n",
    "print(learning_set.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0          0\n",
      "label               0\n",
      "urls_count          0\n",
      "protocol            0\n",
      "contains_ip         0\n",
      "url_length          0\n",
      "TLD_alpha           0\n",
      "subdomain_level    84\n",
      "slash_count         0\n",
      "dots_count          0\n",
      "hyphens_count       0\n",
      "has_non_latin       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(learning_set.isna().sum())\n",
    "learning_set.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wybieranie X i y\n",
    "X:\n",
    "<ul>\n",
    "<li> urls_count </li>\n",
    "<li>protocol </li>\n",
    "<li> contains_ip </li>\n",
    "<li> url_length </li>\n",
    "<li> TLD_alpha </li>\n",
    "<li> subdomain_level </li>\n",
    "<li> slash_count </li>\n",
    "<li> dots_count </li>\n",
    "<li> hyphens_count </li>\n",
    "<li> has_non_latin </li>\n",
    "</ul>\n",
    "y:\n",
    "<ul>\n",
    "    <li> label </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41632, 10) (41632,)\n"
     ]
    }
   ],
   "source": [
    "X = learning_set.loc[:, 'urls_count':'has_non_latin'].values\n",
    "y = learning_set.loc[: , 'label'].values\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rozdzielanie X, y na treningowe i testowe zestawy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalizujemy wartość <b><i>X</i></b>-ów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33305, 10) (8327, 10) (33305,) (8327,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych parametrów dla <i>KNeighborsClassifier</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla KNeighborsClassifier:\n",
      "n_neighbors: 13\n",
      "p: 1\n",
      "weights: distance\n",
      "Uzyskana precyzja:  0.8729022068366331\n",
      "Precyzja zestawu testowego: 0.8734238020895881\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "params = {\n",
    "    'n_neighbors': np.arange(1, 15, 1),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'p': [1, 2]\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn, param_grid=params, cv=kf)\n",
    "knn_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Najlepsze parametry dla KNeighborsClassifier:')\n",
    "for p, val in knn_cv.best_params_.items():\n",
    "    print('{}: {}'.format(p, val), end='\\n')\n",
    "print('Uzyskana precyzja: ', knn_cv.best_score_)\n",
    "\n",
    "best_knn = knn_cv.best_estimator_\n",
    "test_accuracy = best_knn.score(X_test, y_test)\n",
    "print(\"Precyzja zestawu testowego:\", test_accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych parametrów dla <i>LogisticRegression</i>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla LogisticRegression:\n",
      "C: 10\n",
      "penalty: l2\n",
      "Uzyskana precyzja:  0.7300107493550115\n",
      "Precyzja zestawu testowego: 0.7341179296265161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Patryk\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.72688811        nan 0.72853946        nan 0.72974052\n",
      "        nan 0.72980057        nan 0.73001075]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "params = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10] \n",
    "}\n",
    "logreg_forest = LogisticRegression()\n",
    "logreg_cv = GridSearchCV(logreg_forest, param_grid=params, cv=kf)\n",
    "logreg_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Najlepsze parametry dla LogisticRegression:')\n",
    "for p, val in logreg_cv.best_params_.items():\n",
    "    print('{}: {}'.format(p, val), end='\\n')\n",
    "print('Uzyskana precyzja: ', logreg_cv.best_score_)\n",
    "\n",
    "best_logreg = logreg_cv.best_estimator_\n",
    "test_accuracy = best_logreg.score(X_test, y_test)\n",
    "print(\"Precyzja zestawu testowego:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych parametrów dla <i>DecisionTreeClassifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla DecisionTreeClassifier:\n",
      "criterion: gini\n",
      "max_depth: None\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 2\n",
      "Uzyskana precyzja:  0.8711907602071537\n",
      "Precyzja zestawu testowego: 0.8698210640086466\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "params = {\n",
    "    'criterion': ['gini', 'entropy'],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]  \n",
    "}\n",
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = GridSearchCV(tree, param_grid=params, cv=kf)\n",
    "tree_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Najlepsze parametry dla DecisionTreeClassifier:')\n",
    "for p, val in tree_cv.best_params_.items():\n",
    "    print('{}: {}'.format(p, val), end='\\n')\n",
    "print('Uzyskana precyzja: ', tree_cv.best_score_)\n",
    "\n",
    "best_tree = tree_cv.best_estimator_\n",
    "test_accuracy = best_tree.score(X_test, y_test)\n",
    "print(\"Precyzja zestawu testowego:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych parametrów dla <i>RandomForestClassifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najlepsze parametry dla RandomForestClassifier:\n",
      "max_depth: None\n",
      "min_samples_leaf: 1\n",
      "min_samples_split: 10\n",
      "n_estimators: 200\n",
      "Uzyskana precyzja:  0.8757846731617223\n",
      "Precyzja zestawu testowego: 0.8741443497057764\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "params = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 15],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4] \n",
    "}\n",
    "rand_forest = RandomForestClassifier()\n",
    "rand_forest_cv = GridSearchCV(rand_forest, param_grid=params, cv=kf)\n",
    "rand_forest_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Najlepsze parametry dla RandomForestClassifier:')\n",
    "for p, val in rand_forest_cv.best_params_.items():\n",
    "    print('{}: {}'.format(p, val), end='\\n')\n",
    "print('Uzyskana precyzja: ', rand_forest_cv.best_score_)\n",
    "\n",
    "best_rand_forest = rand_forest_cv.best_estimator_\n",
    "test_accuracy = best_rand_forest.score(X_test, y_test)\n",
    "print(\"Precyzja zestawu testowego:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Szukanie najlepszych parametrów dla <i>SVM Classifier</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "kf = KFold(n_splits=6, shuffle=True, random_state=42)\n",
    "params = {\n",
    "    'C': [0.1, 1, 10], \n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto', 0.1, 1]\n",
    "}\n",
    "svm = SVC()\n",
    "svm_cv = GridSearchCV(svm, param_grid=params, cv=kf)\n",
    "svm_cv.fit(X_train, y_train)\n",
    "\n",
    "print('Najlepsze parametry dla SVM Classifier:')\n",
    "for p, val in svm_cv.best_params_.items():\n",
    "    print('{}: {}'.format(p, val), end='\\n')\n",
    "print('Uzyskana precyzja: ', svm_cv.best_score_)\n",
    "\n",
    "best_svm = svm_cv.best_estimator_\n",
    "test_accuracy = best_svm.score(X_test, y_test)\n",
    "print(\"Precyzja zestawu testowego:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(svm_cv.cv_results_.keys())\n",
    "print(svm_cv.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ewaluacja modeli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'KNeighborsClassifier': KNeighborsClassifier(n_neighbors=13, p=1, weights='distance'),\n",
    "    'LogisticRegression': LogisticRegression(C=10, penalty='l2'),\n",
    "    'DecisionTreeClassifier': DecisionTreeClassifier(criterion='gini', max_depth=None, min_samples_leaf=1, min_samples_split=2),\n",
    "    'RandomForestClassifier': RandomForestClassifier(max_depth=None, min_samples_leaf=1, min_samples_split=10, n_estimators=50),\n",
    "    'SVM Classifier': SVC(C=10, gamma=1, kernel='rbf')\n",
    "}\n",
    "\n",
    "results = []\n",
    "for model in models.values():\n",
    "    kf = KFold(n_splits=6, shuffle=True, random_state=10)\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=kf)\n",
    "    results.append(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8')\n",
    "fig, ax = plt.subplots(figsize=(16, 12))\n",
    "\n",
    "boxplot = ax.boxplot(\n",
    "    results,\n",
    "    labels=models.keys(),\n",
    "    patch_artist=True,\n",
    "    boxprops=dict(edgecolor='black'),\n",
    "    whiskerprops=dict(linewidth=1),\n",
    "    capprops=dict(linewidth=1),\n",
    "    medianprops=dict(color='black', linewidth=1),\n",
    "    widths=0.2,\n",
    ")\n",
    "\n",
    "box_colors = ['#FFB6C1', '#ADD8E6', '#90EE90', '#FFFFE0', '#FFC0CB']\n",
    "for box, color in zip(boxplot['boxes'], box_colors):\n",
    "    box.set(facecolor=color)\n",
    "\n",
    "ax.set_title('Wyniki walidacji krzyżowej', fontsize=24)\n",
    "ax.tick_params(axis='both', labelsize=17)\n",
    "ax.set_xlabel('Model', fontsize=20)\n",
    "ax.set_ylabel('Precyzja', fontsize=20)\n",
    "ax.set_ylim(0.70, 0.9)\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nauczanie najskuteczniejszego modelu\n",
    "Najlepszy okazał się <b><i>RandomForestClassifier</i></b>\n",
    "<ul>\n",
    "    <li>Accuracy ~[wyliczyc] &plusmn; [wyliczyc]</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "random_forest = RandomForestClassifier(max_depth=None,\n",
    "                                       min_samples_leaf=1,\n",
    "                                       min_samples_split=10,\n",
    "                                       n_estimators=50)\n",
    "rand_forest.fit(X_train, y_train)\n",
    "y_pred = rand_forest.predict(X_test)\n",
    "confusion_matrix = skm.confusion_matrix(y_test, y_pred)\n",
    "\n",
    "target_names = ['safe', 'phishing']\n",
    "class_report = skm.classification_report(y_test, y_pred, target_names=target_names)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Walidacja wybranego modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')\n",
    "cm_display = skm.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix,\n",
    "    display_labels=['safe', 'phishing'])\n",
    "\n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.show()\n",
    "\n",
    "# Wartości względne\n",
    "cm_display = skm.ConfusionMatrixDisplay(\n",
    "    confusion_matrix=confusion_matrix/np.sum(confusion_matrix),\n",
    "    display_labels=['safe', 'phishing'])\n",
    "    \n",
    "cm_display.plot(cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test na przykładzie z żyćka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mail_example = {\n",
    "'sender': 'Marcin Sawiński <Marcin.Sawinski@ue.poznan.pl>',\n",
    "'subject': 'Projekty zaliczeniowe z PSI',\n",
    "'body': '''\n",
    "        Drodzy Studenci,\n",
    "\n",
    "        Chciałbym Was prosić o zapisanie w arkuszu tematów projektów zaliczeniowych oraz wskazanie osób w zespołach (numer teamu przy nazwisku).\n",
    "\n",
    "        https://uniekonpoznan.sharepoint.com/:x:/s/AI_2023_2024/EQ5avb31cRpAliTAmGtxQ1gB5_YtB0YJTh3c9t7n30uLdQ?e=yLzaTU\n",
    "\n",
    "        Pozdrawiam,\n",
    "\n",
    "        Marcin Sawinski\n",
    "        --\n",
    "        Wiadomość wysłana przez system USOS.\n",
    "        Łączna liczba adresatów tej wiadomości: 117\n",
    "\n",
    "        Nadawcą korespondencji i jednocześnie administratorem Państwa danych osobowych jest Uniwersytet Ekonomiczny w Poznaniu,\n",
    "        al. Niepodległości 10, 61-875 Poznań, z którym można skontaktować się listownie lub poprzez wiadomość e-mail (rodo@ue.poznan.pl)\n",
    "        Państwa dane osobowe przetwarzane będą w celu prowadzenia niniejszej korespondencji i przez czas jej trwania. Przysługuje\n",
    "        Państwu prawo dostępu do danych, ich sprostowania, ograniczenia przetwarzania, usunięcia, żądania sprzeciwu wobec\n",
    "        przetwarzania oraz wniesienia skargi do Prezesa Urzędu Ochrony Danych Osobowych. Szczegółowe informacje na temat ochrony\n",
    "        danych osobowych dostępne są w Polityce prywatności.\n",
    "'''\n",
    "}\n",
    "#TODO: DOKOŃCZYĆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rezultat projektu\n",
    "Przy pomocy <b><i>RandomForestClassifier</i></b> udało się wytrenować model z wynikami:\n",
    "<ul>\n",
    "    <li> (accuracy) ~     </li>   \n",
    "    <li> (recall) ~       </li>\n",
    "    <li> (F1) ~       </li>\n",
    "</ul>\n",
    "</br>\n",
    "Problemy podczas projektu\n",
    "<ul>\n",
    "    <li> dostęp do API </li>\n",
    "    <ul>\n",
    "        <li> brak sprawdzania domen w blacklistach </li>\n",
    "        <li> brak sprawdzania adresów e-mail w blacklistach </li>\n",
    "        <li> słabe/brak informacji o szyfrowaniu SSL </li>\n",
    "        <li> brak sprawdzania wieku domeny\n",
    "    </ul>\n",
    "    <li> Dane zbierane w latach 2008-2022 </li>\n",
    "    <li> Człowiek minimalnie obeznany w internecie </br>poradziłby sobie z klasyfikowaniem ataków phishingowych z datasetu.\n",
    "\n",
    "</ul>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
